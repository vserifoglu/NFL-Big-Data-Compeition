{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71fafb19-75ed-444c-8477-92ac4f04af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520805e3-98fb-4525-a0af-913087329c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/train'\n",
    "SUPP_FILE = '../data/supplementary_data.csv'\n",
    "REPORT_FILE = '../data/dataset_inspection_results.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab84555-e3d6-4ca0-8f77-1080c3681072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Deep Inspection of ../data/train...\n",
      "   Loading Week 1 data for analysis...\n",
      "‚úÖ Inspection Complete. Results saved to ../data/dataset_inspection_results.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def inspect_dataset():\n",
    "    print(f\"üöÄ Starting Deep Inspection of {DATA_DIR}...\")\n",
    "    \n",
    "    with open(REPORT_FILE, 'w') as f:\n",
    "        f.write(\"üèà BIG DATA BOWL 2026: RAW DATASET INSPECTION REPORT\\n\")\n",
    "        f.write(\"====================================================\\n\\n\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # PART 1 & 2: (Kept brief as per previous logic)\n",
    "        # ---------------------------------------------------------\n",
    "        input_files = sorted(glob.glob(os.path.join(DATA_DIR, 'input_*.csv')))\n",
    "        output_files = sorted(glob.glob(os.path.join(DATA_DIR, 'output_*.csv')))\n",
    "        \n",
    "        f.write(f\"Files Found: {len(input_files)} Input pairs, {len(output_files)} Output pairs.\\n\\n\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # PART 3: DEEP DIVE SAMPLE (WEEK 1) - WITH DROPOUT ANALYSIS\n",
    "        # ---------------------------------------------------------\n",
    "        f.write(\"PART 3: WEEK 1 DEEP DIVE & SPARSITY PROOF\\n\")\n",
    "        f.write(\"-----------------------------------------\\n\")\n",
    "        \n",
    "        if input_files and output_files:\n",
    "            # Load Week 1 Pair\n",
    "            w1_input_path = input_files[0]\n",
    "            w1_output_path = output_files[0]\n",
    "            \n",
    "            print(\"   Loading Week 1 data for analysis...\")\n",
    "            df_in = pd.read_csv(w1_input_path, low_memory=False)\n",
    "            df_out = pd.read_csv(w1_output_path, low_memory=False)\n",
    "            \n",
    "            # --- 3.7 ATTRITION & SPARSITY ANALYSIS (NEW) ---\n",
    "            f.write(\"3.7 PLAYER DROPOUT & TEMPORAL SPARSITY ANALYSIS\\n\")\n",
    "            f.write(\"   (Proving that pre_throw frames > post_throw and identifying missing players)\\n\\n\")\n",
    "\n",
    "            # A. Temporal Sparsity (Frame Counts)\n",
    "            # Group by play and count unique frames\n",
    "            in_frames = df_in.groupby(['game_id', 'play_id'])['frame_id'].nunique()\n",
    "            out_frames = df_out.groupby(['game_id', 'play_id'])['frame_id'].nunique()\n",
    "            \n",
    "            # Merge series to compare\n",
    "            frame_comp = pd.concat([in_frames, out_frames], axis=1, keys=['in_frames', 'out_frames']).dropna()\n",
    "            frame_comp['ratio_in_to_out'] = frame_comp['in_frames'] / frame_comp['out_frames']\n",
    "            \n",
    "            f.write(\"   A. Temporal Differences (Frame Counts):\\n\")\n",
    "            f.write(f\"      - Avg Pre-Throw Frames:  {frame_comp['in_frames'].mean():.2f}\\n\")\n",
    "            f.write(f\"      - Avg Post-Throw Frames: {frame_comp['out_frames'].mean():.2f}\\n\")\n",
    "            f.write(f\"      - Conclusion: On average, input files are {frame_comp['ratio_in_to_out'].mean():.2f}x longer than output files.\\n\\n\")\n",
    "\n",
    "            # B. Entity Dropout (Players Disappearing)\n",
    "            f.write(\"   B. Entity Dropout (Players vanishing in Output):\\n\")\n",
    "            \n",
    "            # Get unique NFL IDs per play for Input and Output\n",
    "            # We filter out NaN nfl_ids (usually the football)\n",
    "            in_players = df_in.dropna(subset=['nfl_id']).groupby(['game_id', 'play_id'])['nfl_id'].apply(set)\n",
    "            out_players = df_out.dropna(subset=['nfl_id']).groupby(['game_id', 'play_id'])['nfl_id'].apply(set)\n",
    "            \n",
    "            # Merge to compare sets\n",
    "            dropout_df = pd.concat([in_players, out_players], axis=1, keys=['in_set', 'out_set']).dropna()\n",
    "            \n",
    "            # Calculate dropout\n",
    "            # \"Dropout\" = IDs in Input that are NOT in Output\n",
    "            dropout_df['missing_ids'] = dropout_df.apply(lambda x: x['in_set'] - x['out_set'], axis=1)\n",
    "            dropout_df['missing_count'] = dropout_df['missing_ids'].apply(len)\n",
    "            \n",
    "            total_plays_w1 = len(dropout_df)\n",
    "            plays_with_dropout = len(dropout_df[dropout_df['missing_count'] > 0])\n",
    "            avg_missing = dropout_df['missing_count'].mean()\n",
    "            max_missing = dropout_df['missing_count'].max()\n",
    "            \n",
    "            f.write(f\"      - Total Plays Analyzed: {total_plays_w1}\\n\")\n",
    "            f.write(f\"      - Plays with AT LEAST ONE missing player: {plays_with_dropout} ({plays_with_dropout/total_plays_w1*100:.2f}%)\\n\")\n",
    "            f.write(f\"      - Avg Missing Players per Play: {avg_missing:.2f}\\n\")\n",
    "            f.write(f\"      - Max Missing Players in a single play: {max_missing}\\n\\n\")\n",
    "            \n",
    "            # C. Identify WHO is disappearing (Roles)\n",
    "            if plays_with_dropout > 0:\n",
    "                f.write(\"   C. Profile of Vanishing Players (Sample):\\n\")\n",
    "                # Get a sample play with high dropout\n",
    "                bad_play = dropout_df.sort_values('missing_count', ascending=False).index[0]\n",
    "                missing_ids_list = list(dropout_df.loc[bad_play, 'missing_ids'])\n",
    "                \n",
    "                f.write(f\"      Sample Play (Game {bad_play[0]}, Play {bad_play[1]}):\\n\")\n",
    "                f.write(f\"      Missing {len(missing_ids_list)} players in Output.\\n\")\n",
    "                \n",
    "                # Look up these IDs in the input file to see their roles\n",
    "                missing_details = df_in[\n",
    "                    (df_in.game_id == bad_play[0]) & \n",
    "                    (df_in.play_id == bad_play[1]) & \n",
    "                    (df_in.nfl_id.isin(missing_ids_list))\n",
    "                ][['nfl_id', 'player_name', 'player_role', 'player_position']].drop_duplicates()\n",
    "                \n",
    "                f.write(missing_details.to_string(index=False))\n",
    "                f.write(\"\\n\\n\")\n",
    "                \n",
    "                # Check specific hypothesis: Do specific positions disappear more?\n",
    "                # (Simple check: are they mostly linemen?)\n",
    "                linemen = missing_details['player_position'].isin(['T', 'G', 'C', 'DT', 'NT', 'DE']).mean()\n",
    "                f.write(f\"      Observation: {linemen*100:.1f}% of missing players in this sample are Linemen.\\n\")\n",
    "                f.write(\"      (Hypothesis: Tracking data often drops interior linemen post-throw if they are not near the play.)\\n\\n\")\n",
    "\n",
    "            # Clean up\n",
    "            del df_in, df_out, dropout_df, in_frames, out_frames\n",
    "            gc.collect()\n",
    "\n",
    "        f.write(\"Inspection complete. See 'data_inspection_results.txt' for details.\")\n",
    "\n",
    "    print(f\"‚úÖ Inspection Complete. Results saved to {REPORT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18873db1-d491-4ef1-8922-aff2bf3c11f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Deep Inspection of ../data/train...\n",
      "Index(['game_id', 'season', 'week', 'game_date', 'game_time_eastern',\n",
      "       'home_team_abbr', 'visitor_team_abbr', 'play_id', 'play_description',\n",
      "       'quarter', 'game_clock', 'down', 'yards_to_go', 'possession_team',\n",
      "       'defensive_team', 'yardline_side', 'yardline_number',\n",
      "       'pre_snap_home_score', 'pre_snap_visitor_score',\n",
      "       'play_nullified_by_penalty', 'pass_result', 'pass_length',\n",
      "       'offense_formation', 'receiver_alignment', 'route_of_targeted_receiver',\n",
      "       'play_action', 'dropback_type', 'dropback_distance',\n",
      "       'pass_location_type', 'defenders_in_the_box', 'team_coverage_man_zone',\n",
      "       'team_coverage_type', 'penalty_yards', 'pre_penalty_yards_gained',\n",
      "       'yards_gained', 'expected_points', 'expected_points_added',\n",
      "       'pre_snap_home_team_win_probability',\n",
      "       'pre_snap_visitor_team_win_probability',\n",
      "       'home_team_win_probability_added', 'visitor_team_win_probility_added'],\n",
      "      dtype='object')\n",
      "sdfwefwE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14603/2443698392.py:19: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  supp_df = pd.read_csv(SUPP_FILE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id',\n",
      "       'play_direction', 'absolute_yardline_number', 'player_name',\n",
      "       'player_height', 'player_weight', 'player_birth_date',\n",
      "       'player_position', 'player_side', 'player_role', 'x', 'y', 's', 'a',\n",
      "       'dir', 'o', 'num_frames_output', 'ball_land_x', 'ball_land_y'],\n",
      "      dtype='object') Sdfwe\n",
      "Scanning w01...\n",
      "Scanning w02...\n",
      "Scanning w03...\n",
      "Scanning w04...\n",
      "Scanning w05...\n",
      "Scanning w06...\n",
      "Scanning w07...\n",
      "Scanning w08...\n",
      "Scanning w09...\n",
      "Scanning w10...\n",
      "Scanning w11...\n",
      "Scanning w12...\n",
      "Scanning w13...\n",
      "Scanning w14...\n",
      "Scanning w15...\n",
      "Scanning w16...\n",
      "Scanning w17...\n",
      "Scanning w18...\n",
      "‚úÖ Inspection Complete. Report saved to ../data/dataset_inspection_report_v2.txt\n"
     ]
    }
   ],
   "source": [
    "REPORT_FILE = '../data/dataset_inspection_report_v2.txt'\n",
    "\n",
    "\n",
    "def inspect_dataset():\n",
    "    print(f\"üöÄ Starting Deep Inspection of {DATA_DIR}...\")\n",
    "    \n",
    "    with open(REPORT_FILE, 'w') as f:\n",
    "        f.write(\"üèà BIG DATA BOWL 2026: RAW DATASET INSPECTION REPORT\\n\")\n",
    "        f.write(f\"Generated on: {pd.Timestamp.now()}\\n\")\n",
    "        f.write(\"====================================================\\n\\n\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # PART 1: SUPPLEMENTARY DATA INSPECTION\n",
    "        # ---------------------------------------------------------\n",
    "        f.write(\"PART 1: SUPPLEMENTARY DATA (METADATA)\\n\")\n",
    "        f.write(\"-------------------------------------\\n\")\n",
    "        \n",
    "        if os.path.exists(SUPP_FILE):\n",
    "            supp_df = pd.read_csv(SUPP_FILE)\n",
    "            f.write(f\"File: {SUPP_FILE}\\n\")\n",
    "            f.write(f\"Shape: {supp_df.shape}\\n\")\n",
    "            f.write(f\"Columns: {list(supp_df.columns)}\\n\\n\")\n",
    "            \n",
    "            # Critical Field Analysis\n",
    "            f.write(\">>> Coverage Types Distribution:\\n\")\n",
    "            f.write(supp_df['team_coverage_man_zone'].value_counts(dropna=False).to_string())\n",
    "            f.write(\"\\n\\n\")\n",
    "            \n",
    "            f.write(\">>> Pass Results:\\n\")\n",
    "            f.write(supp_df['pass_result'].value_counts(dropna=False).to_string())\n",
    "            f.write(\"\\n\\n\")\n",
    "            \n",
    "            f.write(\">>> Null Values in Critical Columns:\\n\")\n",
    "            critical_cols = ['game_id', 'play_id', 'team_coverage_type', 'pass_length']\n",
    "            print(supp_df.columns)\n",
    "            f.write(supp_df[critical_cols].isnull().sum().to_string())\n",
    "            print(\"sdfwefwE\")\n",
    "            f.write(\"\\n\\n\")\n",
    "        else:\n",
    "            f.write(f\"‚ùå ERROR: Supplementary file not found at {SUPP_FILE}\\n\\n\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # PART 2: TRACKING DATA FILE TOPOLOGY\n",
    "        # ---------------------------------------------------------\n",
    "        f.write(\"PART 2: TRACKING DATA TOPOLOGY\\n\")\n",
    "        f.write(\"------------------------------\\n\")\n",
    "        input_files = sorted(glob.glob(os.path.join(DATA_DIR, 'input_*.csv')))\n",
    "        output_files = sorted(glob.glob(os.path.join(DATA_DIR, 'output_*.csv')))\n",
    "        \n",
    "        f.write(f\"Total Input Files (Pre-Throw): {len(input_files)}\\n\")\n",
    "        f.write(f\"Total Output Files (Post-Throw): {len(output_files)}\\n\\n\")\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # PART 3: DEEP DIVE SAMPLE (WEEK 1)\n",
    "        # ---------------------------------------------------------\n",
    "        f.write(\"PART 3: DEEP SAMPLE ANALYSIS (WEEK 1)\\n\")\n",
    "        f.write(\"-------------------------------------\\n\")\n",
    "        \n",
    "        if input_files and output_files:\n",
    "            # Load Week 1 Pair\n",
    "            w1_input_path = input_files[0]\n",
    "            w1_output_path = output_files[0]\n",
    "            \n",
    "            f.write(f\"Loading Sample Pair:\\n  - {os.path.basename(w1_input_path)}\\n  - {os.path.basename(w1_output_path)}\\n\\n\")\n",
    "            \n",
    "            df_in = pd.read_csv(w1_input_path, low_memory=False)\n",
    "            df_out = pd.read_csv(w1_output_path, low_memory=False)\n",
    "            \n",
    "            # 3.1 Column Integrity\n",
    "            f.write(\"3.1 Column Consistency Check:\\n\")\n",
    "            in_cols = set(df_in.columns)\n",
    "            out_cols = set(df_out.columns)\n",
    "            \n",
    "            if in_cols == out_cols:\n",
    "                f.write(\"‚úÖ Input and Output files have identical schemas.\\n\")\n",
    "                f.write(f\"Columns: {list(df_in.columns)}\\n\\n\")\n",
    "            else:\n",
    "                f.write(\"‚ö†Ô∏è Schema Mismatch detected!\\n\")\n",
    "                f.write(f\"Only in Input: {in_cols - out_cols}\\n\")\n",
    "                f.write(f\"Only in Output: {out_cols - in_cols}\\n\\n\")\n",
    "\n",
    "            # 3.2 Basic Stats\n",
    "            f.write(\"3.2 Sample Statistics (Week 1):\\n\")\n",
    "            f.write(f\"Input Rows (Pre-Throw): {len(df_in):,}\\n\")\n",
    "            f.write(f\"Output Rows (Post-Throw): {len(df_out):,}\\n\")\n",
    "            \n",
    "            # 3.3 Stitching Logic Check\n",
    "            f.write(\"\\n3.3 Stitching Logic Inspection:\\n\")\n",
    "            sample_play = df_in[['game_id', 'play_id']].iloc[0]\n",
    "            g_id, p_id = sample_play['game_id'], sample_play['play_id']\n",
    "            \n",
    "            sample_in = df_in[(df_in.game_id == g_id) & (df_in.play_id == p_id)]\n",
    "            sample_out = df_out[(df_out.game_id == g_id) & (df_out.play_id == p_id)]\n",
    "            \n",
    "            max_frame_in = sample_in['frame_id'].max()\n",
    "            min_frame_out = sample_out['frame_id'].min()\n",
    "            \n",
    "            f.write(f\"Sample Play ({g_id} - {p_id}):\\n\")\n",
    "            f.write(f\"  - Max Input Frame: {max_frame_in}\\n\")\n",
    "            f.write(f\"  - Min Output Frame: {min_frame_out} (Should be 1)\\n\")\n",
    "            f.write(f\"  - Gap Analysis: Input ends at {max_frame_in}, Output starts at {min_frame_out}. Offset required.\\n\\n\")\n",
    "\n",
    "            # 3.4 Player Roles\n",
    "            f.write(\"3.4 Player Roles in Tracking Data:\\n\")\n",
    "            roles = df_in['player_role'].dropna().unique()\n",
    "            f.write(f\"{', '.join(roles)}\\n\\n\")\n",
    "            \n",
    "            # 3.5 Coordinate Range (Normalization Check)\n",
    "            f.write(\"3.5 Coordinate Bounds (Raw Data):\\n\")\n",
    "            f.write(f\"  - X Range: {df_in['x'].min()} to {df_in['x'].max()}\\n\")\n",
    "            f.write(f\"  - Y Range: {df_in['y'].min()} to {df_in['y'].max()}\\n\")\n",
    "            f.write(\"  *Note: If X goes > 100, standard NFL coords (0-120) are likely used.*\\n\\n\")\n",
    "\n",
    "            # 3.6 Ball Landing Spot availability\n",
    "            f.write(\"3.6 Ball Landing Spot Availability:\\n\")\n",
    "            print(df_in.columns, \"Sdfwe\")\n",
    "            null_ball = df_in['ball_land_x'].isnull().mean() * 100\n",
    "            f.write(f\"  - Percentage of rows with Missing 'ball_land_x': {null_ball:.2f}%\\n\")\n",
    "            if null_ball > 0:\n",
    "                f.write(\"  - (This is expected if ball_land is only populated on specific frames or plays)\\n\\n\")\n",
    "\n",
    "            # Clean up memory\n",
    "            del df_in, df_out, sample_in, sample_out\n",
    "            gc.collect()\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # PART 4: AGGREGATE SCAN (ALL FILES)\n",
    "        # ---------------------------------------------------------\n",
    "        f.write(\"PART 4: AGGREGATE SCAN (ALL WEEKS)\\n\")\n",
    "        f.write(\"----------------------------------\\n\")\n",
    "        \n",
    "        total_rows = 0\n",
    "        total_games = set()\n",
    "        total_plays = set() # Store tuples (game_id, play_id)\n",
    "        \n",
    "        # Iterate through pairs to save memory\n",
    "        for i_path, o_path in zip(input_files, output_files):\n",
    "            week_num = i_path.split('_')[-1].split('.')[0] # e.g., w01\n",
    "            print(f\"Scanning {week_num}...\")\n",
    "            \n",
    "            # Just read minimal columns to get counts\n",
    "            cols_to_load = ['game_id', 'play_id']\n",
    "            \n",
    "            # Read chunks to avoid memory spike\n",
    "            df_i = pd.read_csv(i_path, usecols=cols_to_load, low_memory=False)\n",
    "            df_o = pd.read_csv(o_path, usecols=cols_to_load, low_memory=False)\n",
    "            \n",
    "            current_rows = len(df_i) + len(df_o)\n",
    "            total_rows += current_rows\n",
    "            \n",
    "            # Update Unique Sets\n",
    "            week_games = set(df_i['game_id'].unique())\n",
    "            week_plays = set(zip(df_i['game_id'], df_i['play_id']))\n",
    "            \n",
    "            total_games.update(week_games)\n",
    "            total_plays.update(week_plays)\n",
    "            \n",
    "            f.write(f\"  - {week_num}: {current_rows:,} rows | {len(week_games)} games | {len(week_plays)} plays\\n\")\n",
    "            \n",
    "            del df_i, df_o\n",
    "            gc.collect()\n",
    "\n",
    "        f.write(f\"\\nTOTAL DATASET STATS:\\n\")\n",
    "        f.write(f\"  - Total Rows: {total_rows:,}\\n\")\n",
    "        f.write(f\"  - Unique Games: {len(total_games)}\\n\")\n",
    "        f.write(f\"  - Unique Plays: {len(total_plays)}\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Inspection Complete. Report saved to {REPORT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        inspect_dataset()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to run inspection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1265b499-a0a6-49e2-b29c-8edab9d50175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è Analyzing Player Dropout based on Ball Landing Spot...\n",
      "Results saved to ../data/dataset_dropout_logic_inspection.txt\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = '../data/dataset_dropout_logic_inspection.txt'\n",
    "\n",
    "def inspect_dropout_logic():\n",
    "    print(\"üïµÔ∏è Analyzing Player Dropout based on Ball Landing Spot...\")\n",
    "    \n",
    "    # Load Week 1 data\n",
    "    input_files = sorted(glob.glob(os.path.join(DATA_DIR, 'input_*.csv')))\n",
    "    output_files = sorted(glob.glob(os.path.join(DATA_DIR, 'output_*.csv')))\n",
    "    \n",
    "    # We use low_memory=False to ensure columns don't get mixed types\n",
    "    df_in = pd.read_csv(input_files[0], low_memory=False)\n",
    "    df_out = pd.read_csv(output_files[0], low_memory=False)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Analyze a sample of 100 plays\n",
    "    unique_plays = df_in[['game_id', 'play_id']].drop_duplicates().head(100).values\n",
    "    \n",
    "    for g_id, p_id in unique_plays:\n",
    "        # 1. Get the \"Before\" Snapshot: The LAST frame of the Input file\n",
    "        # This is the split-second BEFORE the throw (or the instant of the throw in input data).\n",
    "        play_in = df_in[(df_in.game_id == g_id) & (df_in.play_id == p_id)]\n",
    "        if play_in.empty: continue\n",
    "            \n",
    "        last_frame_id = play_in['frame_id'].max()\n",
    "        snapshot = play_in[play_in['frame_id'] == last_frame_id].copy()\n",
    "        \n",
    "        # 2. Get the Ball Landing Spot (From the Input columns)\n",
    "        # Note: ball_land_x/y only exist in the Input file.\n",
    "        if 'ball_land_x' not in snapshot.columns:\n",
    "            continue\n",
    "            \n",
    "        ball_land_x = snapshot['ball_land_x'].iloc[0]\n",
    "        ball_land_y = snapshot['ball_land_y'].iloc[0]\n",
    "        \n",
    "        if pd.isna(ball_land_x) or pd.isna(ball_land_y):\n",
    "            continue\n",
    "\n",
    "        # 3. Who Survived? (Check Output Frame 1)\n",
    "        # We verify who made it to the \"Moment of the Throw\" data.\n",
    "        play_out = df_out[(df_out.game_id == g_id) & (df_out.play_id == p_id)]\n",
    "        survivor_ids = set(play_out['nfl_id'].unique())\n",
    "        \n",
    "        # 4. Calculate Distance to the LANDING SPOT\n",
    "        # We calculate this on the Snapshot because the \"Ghosts\" are still present here.\n",
    "        snapshot['dist_to_landing'] = np.sqrt(\n",
    "            (snapshot['x'] - ball_land_x)**2 + \n",
    "            (snapshot['y'] - ball_land_y)**2\n",
    "        )\n",
    "        \n",
    "        # 5. Tag Survivors vs Ghosts\n",
    "        snapshot = snapshot.dropna(subset=['nfl_id'])\n",
    "        snapshot['status'] = snapshot['nfl_id'].apply(lambda x: 'Survivor' if x in survivor_ids else 'Ghost')\n",
    "        \n",
    "        results.append(snapshot[['game_id', 'play_id', 'nfl_id', 'player_role', 'dist_to_landing', 'status']])\n",
    "\n",
    "    # --- AGGREGATE RESULTS ---\n",
    "    if not results:\n",
    "        print(\"No valid plays found.\")\n",
    "        return\n",
    "\n",
    "    all_data = pd.concat(results)\n",
    "    \n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        f.write(\"THE IRRELEVANCE HYPOTHESIS TEST\\n\")\n",
    "        f.write(\"===============================\\n\")\n",
    "        f.write(\"Hypothesis: Players are dropped in the Output file because they are far from the landing spot.\\n\\n\")\n",
    "        \n",
    "        # 1. Compare Distances\n",
    "        stats = all_data.groupby('status')['dist_to_landing'].describe()\n",
    "        f.write(\"1. Distance to Landing Spot (Stats):\\n\")\n",
    "        f.write(stats.to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # 2. The Danger Check\n",
    "        # Are there Ghosts within 15 yards of where the ball landed?\n",
    "        THRESHOLD = 15.0\n",
    "        danger_ghosts = all_data[(all_data['status'] == 'Ghost') & (all_data['dist_to_landing'] < THRESHOLD)]\n",
    "        \n",
    "        f.write(f\"2. Danger Ghosts (< {THRESHOLD} yards from landing):\\n\")\n",
    "        f.write(f\"   Count: {len(danger_ghosts)}\\n\")\n",
    "        \n",
    "        if len(danger_ghosts) > 0:\n",
    "            f.write(\"   ‚ö†Ô∏è WARNING: Some players close to the catch point are disappearing!\\n\")\n",
    "            f.write(\"   Sample of these missing players:\\n\")\n",
    "            f.write(danger_ghosts[['game_id', 'play_id', 'player_role', 'dist_to_landing']].head(15).to_string())\n",
    "        else:\n",
    "            f.write(\"   ‚úÖ SUCCESS: All missing players were > 15 yards from the landing spot.\\n\")\n",
    "            f.write(\"   (This confirms the dataset filters out irrelevant players.)\\n\")\n",
    "            \n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        # 3. Role Analysis\n",
    "        if 'player_role' in all_data.columns:\n",
    "            targets = all_data[all_data['player_role'] == 'Targeted Receiver']\n",
    "            missing_targets = targets[targets['status'] == 'Ghost']\n",
    "            \n",
    "            f.write(f\"3. Missing Targeted Receivers: {len(missing_targets)}\\n\")\n",
    "            if len(missing_targets) > 0:\n",
    "                f.write(\"   ‚ùå CRITICAL: Targeted Receivers are dropping out!\\n\")\n",
    "            else:\n",
    "                f.write(\"   ‚úÖ PASS: Targeted Receiver always survives.\\n\")\n",
    "\n",
    "    print(f\"Results saved to {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_dropout_logic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8997aa61-e1d0-4753-8291-7a837a614b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Inspecting Physics Variables (s, a, dir, o)...\n",
      "Inspection complete. Check ../data/physics_vars_inspection.txt\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = '../data/physics_vars_inspection.txt'\n",
    "\n",
    "def inspect_physics_vars():\n",
    "    print(\"üî¨ Inspecting Physics Variables (s, a, dir, o)...\")\n",
    "    \n",
    "    input_files = sorted(glob.glob(os.path.join(DATA_DIR, 'input_*.csv')))\n",
    "    output_files = sorted(glob.glob(os.path.join(DATA_DIR, 'output_*.csv')))\n",
    "    \n",
    "    # Load Week 1 pair\n",
    "    df_in = pd.read_csv(input_files[0], nrows=1000) # Just need headers and a few rows\n",
    "    df_out = pd.read_csv(output_files[0], nrows=1000)\n",
    "    \n",
    "    PHYSICS_COLS = ['s', 'a', 'dir', 'o']\n",
    "    \n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        f.write(\"PHYSICS VARIABLES AVAILABILITY REPORT\\n\")\n",
    "        f.write(\"=======================================\\n\\n\")\n",
    "        \n",
    "        # 1. Check Column Existence\n",
    "        f.write(\"1. Column Existence Check:\\n\")\n",
    "        \n",
    "        in_missing = [c for c in PHYSICS_COLS if c not in df_in.columns]\n",
    "        out_missing = [c for c in PHYSICS_COLS if c not in df_out.columns]\n",
    "        \n",
    "        f.write(f\"   Input Files Missing: {in_missing if in_missing else 'None (All present)'}\\n\")\n",
    "        f.write(f\"   Output Files Missing: {out_missing if out_missing else 'None (All present)'}\\n\\n\")\n",
    "        \n",
    "        # 2. Check for Nulls (in case columns exist but are empty)\n",
    "        f.write(\"2. Data Content Check (Are they full of NaNs?):\\n\")\n",
    "        \n",
    "        f.write(\"   [INPUT FILES]\\n\")\n",
    "        for col in PHYSICS_COLS:\n",
    "            if col in df_in.columns:\n",
    "                null_pct = df_in[col].isnull().mean() * 100\n",
    "                f.write(f\"     - {col}: {null_pct:.1f}% Nulls\\n\")\n",
    "            else:\n",
    "                f.write(f\"     - {col}: COLUMN MISSING\\n\")\n",
    "                \n",
    "        f.write(\"\\n   [OUTPUT FILES]\\n\")\n",
    "        for col in PHYSICS_COLS:\n",
    "            if col in df_out.columns:\n",
    "                null_pct = df_out[col].isnull().mean() * 100\n",
    "                f.write(f\"     - {col}: {null_pct:.1f}% Nulls\\n\")\n",
    "            else:\n",
    "                f.write(f\"     - {col}: COLUMN MISSING\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # 3. Implication Analysis\n",
    "        if out_missing or any(df_out[c].isnull().all() for c in PHYSICS_COLS if c in df_out.columns):\n",
    "            f.write(\"3. CRITICAL IMPLICATIONS:\\n\")\n",
    "            f.write(\"   The Output files lack motion vectors.\\n\")\n",
    "            f.write(\"   IMPACT 1 (Animation): You cannot use 'dir' arrows in visualization.\\n\")\n",
    "            f.write(\"   IMPACT 2 (Normalization): 'data_preprocessor.py' tries to flip 'dir'/'o' for left-moving plays.\\n\")\n",
    "            f.write(\"             If these columns are missing, that code block will crash.\\n\")\n",
    "            f.write(\"   IMPACT 3 (Physics): You must DERIVE speed/direction from x,y changes if needed.\\n\")\n",
    "        else:\n",
    "            f.write(\"3. Status: Green. All physics variables are available.\\n\")\n",
    "\n",
    "    print(f\"Inspection complete. Check {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_physics_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02d82a3a-14be-4a73-b078-5d0abcc332d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING Data...\n",
      "Processing 254917 rows...\n",
      "\n",
      "--- CALCULATING ACCURACY METRICS ---\n",
      "SPEED (s): R2 = 0.9970 | MAE = 0.0853 yds/s\n",
      "ACCEL (a): R2 = 0.4416 | MAE = 0.8248 yds/s¬≤\n",
      "DIR (dir): Mean Angle Error = 6.9227 degrees\n",
      "\n",
      "‚úÖ Validation Sample saved to 'validation_sample.csv'\n",
      "\n",
      "üèÜ RESULT: PASSED. The physics engine is statistically valid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14603/1041425314.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  physics_cols = df.groupby(['game_id', 'play_id', 'nfl_id']).apply(calculate_metrics)\n"
     ]
    }
   ],
   "source": [
    "# This is important to show case our physic validation - and limitations. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "def derive_physics_robust(df):\n",
    "    \"\"\"\n",
    "    CORRECTED: Derives Magnitude of Acceleration (always positive) \n",
    "    to match NFL Tracking Data definition.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
    "    \n",
    "    WINDOW = 7 \n",
    "    POLY = 2\n",
    "    \n",
    "    def calculate_metrics(group):\n",
    "        # Need window length\n",
    "        if len(group) < WINDOW:\n",
    "            return pd.DataFrame({\n",
    "                's_derived': np.nan, \n",
    "                'a_derived': np.nan, \n",
    "                'dir_derived': np.nan\n",
    "            }, index=group.index)\n",
    "            \n",
    "        # 1. VELOCITY VECTORS (1st Derivative)\n",
    "        # deriv=1 means dx/dt\n",
    "        vx = savgol_filter(group['x'], window_length=WINDOW, polyorder=POLY, deriv=1, delta=0.1)\n",
    "        vy = savgol_filter(group['y'], window_length=WINDOW, polyorder=POLY, deriv=1, delta=0.1)\n",
    "        \n",
    "        # 2. ACCELERATION VECTORS (2nd Derivative)\n",
    "        # deriv=2 means d2x/dt2\n",
    "        ax = savgol_filter(group['x'], window_length=WINDOW, polyorder=POLY, deriv=2, delta=0.1)\n",
    "        ay = savgol_filter(group['y'], window_length=WINDOW, polyorder=POLY, deriv=2, delta=0.1)\n",
    "        \n",
    "        # 3. SPEED (Magnitude of Velocity)\n",
    "        s = np.sqrt(vx**2 + vy**2)\n",
    "        \n",
    "        # 4. ACCELERATION (Magnitude of Acceleration Vector)\n",
    "        # This fixes the negative issue. It will now be always positive.\n",
    "        a = np.sqrt(ax**2 + ay**2)\n",
    "        \n",
    "        # 5. DIRECTION\n",
    "        angle_rad = np.arctan2(vy, vx)\n",
    "        angle_deg = np.degrees(angle_rad)\n",
    "        dir_val = (90 - angle_deg) % 360\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            's_derived': s,\n",
    "            'a_derived': a, \n",
    "            'dir_derived': dir_val\n",
    "        }, index=group.index)\n",
    "\n",
    "    physics_cols = df.groupby(['game_id', 'play_id', 'nfl_id']).apply(calculate_metrics)\n",
    "    \n",
    "    # Reset index to handle the multi-index returned by apply\n",
    "    if isinstance(physics_cols, pd.DataFrame):\n",
    "        physics_cols = physics_cols.reset_index(level=[0,1,2], drop=True)\n",
    "    \n",
    "    return df.join(physics_cols)\n",
    "\n",
    "# --- 2. THE VALIDATION RUNNER ---\n",
    "def run_validation():\n",
    "    print(\"LOADING Data...\")\n",
    "    # Adjust path if necessary\n",
    "    df = pd.read_csv('../data/train/input_2023_w18.csv', low_memory=False)\n",
    "    \n",
    "    # Filter for active plays (ignore motionless pre-snap frames if possible, but full set is fine)\n",
    "    # We take a sample to speed it up if the file is huge, or run full.\n",
    "    print(f\"Processing {len(df)} rows...\")\n",
    "    \n",
    "    df_derived = derive_physics_robust(df)\n",
    "    \n",
    "    # Remove NaNs (first/last frames of smoothing window often NaN)\n",
    "    df_clean = df_derived.dropna(subset=['s', 's_derived', 'a', 'a_derived', 'dir', 'dir_derived'])\n",
    "    \n",
    "    print(\"\\n--- CALCULATING ACCURACY METRICS ---\")\n",
    "    \n",
    "    # 1. SPEED Validation\n",
    "    r2_s = r2_score(df_clean['s'], df_clean['s_derived'])\n",
    "    mae_s = mean_absolute_error(df_clean['s'], df_clean['s_derived'])\n",
    "    print(f\"SPEED (s): R2 = {r2_s:.4f} | MAE = {mae_s:.4f} yds/s\")\n",
    "    \n",
    "    # 2. ACCELERATION Validation\n",
    "    r2_a = r2_score(df_clean['a'], df_clean['a_derived'])\n",
    "    mae_a = mean_absolute_error(df_clean['a'], df_clean['a_derived'])\n",
    "    print(f\"ACCEL (a): R2 = {r2_a:.4f} | MAE = {mae_a:.4f} yds/s¬≤\")\n",
    "    \n",
    "    # 3. DIRECTION Validation (Needs Vector Logic)\n",
    "    # Problem: 359 is close to 1. Standard MAE fails.\n",
    "    # Solution: Calculate smallest angle difference.\n",
    "    diff = np.abs(df_clean['dir'] - df_clean['dir_derived'])\n",
    "    diff = np.minimum(diff, 360 - diff) # Wraparound logic\n",
    "    mae_dir = np.mean(diff)\n",
    "    \n",
    "    print(f\"DIR (dir): Mean Angle Error = {mae_dir:.4f} degrees\")\n",
    "    \n",
    "    # 4. Save Comparison for Inspection\n",
    "    out_cols = ['game_id', 'play_id', 'nfl_id', 'frame_id', \n",
    "                's', 's_derived', 'diff_s',\n",
    "                'a', 'a_derived', 'diff_a',\n",
    "                'dir', 'dir_derived', 'diff_dir_angle']\n",
    "    \n",
    "    df_clean['diff_s'] = df_clean['s'] - df_clean['s_derived']\n",
    "    df_clean['diff_a'] = df_clean['a'] - df_clean['a_derived']\n",
    "    df_clean['diff_dir_angle'] = diff\n",
    "    \n",
    "    df_clean[out_cols].head(1000).to_csv('validation_sample.csv', index=False)\n",
    "    print(\"\\n‚úÖ Validation Sample saved to 'validation_sample.csv'\")\n",
    "    \n",
    "    # 5. Success Check\n",
    "    if r2_s > 0.90:\n",
    "        print(\"\\nüèÜ RESULT: PASSED. The physics engine is statistically valid.\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è RESULT: WARNING. Speed correlation is too low. Check smoothing parameters.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25286583-2d22-4d1a-9943-1b51abb0f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Define file paths based on the pipeline output\n",
    "OUTPUT_DIR = '../data/processed'\n",
    "ANIMATION_FILE = os.path.join(OUTPUT_DIR, 'master_animation_data.csv')\n",
    "SUMMARY_FILE = os.path.join(OUTPUT_DIR, 'reaction_analysis_summary.csv')\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Loads the final processed dataframes.\"\"\"\n",
    "    try:\n",
    "        df_frame = pd.read_csv(ANIMATION_FILE)\n",
    "        df_summary = pd.read_csv(SUMMARY_FILE)\n",
    "        return df_frame, df_summary\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Files not found. Ensure {ANIMATION_FILE} and {SUMMARY_FILE} exist.\")\n",
    "        return None, None\n",
    "\n",
    "# --- Verification Cell 1: Internal Data Integrity Checks ---\n",
    "\n",
    "def run_internal_integrity_checks(df_frame):\n",
    "    \"\"\"Verifies the mathematical stability and data flow of the physics engine.\"\"\"\n",
    "    \n",
    "    markdown = \"### 1. Internal Data Integrity and Physics Validation\\n\"\n",
    "    markdown += \"Verifying that the derived metrics (S, Dir, A) are stable and flow correctly across all frames.\\n\\n\"\n",
    "    \n",
    "    if df_frame is None or df_frame.empty:\n",
    "        markdown += \"üî¥ **DATA LOAD FAILURE.** Cannot run checks.\\n\"\n",
    "        print(markdown)\n",
    "        return\n",
    "\n",
    "    df_post_throw = df_frame[df_frame['phase'] == 'post_throw'].copy()\n",
    "\n",
    "    # 1. NaN Integrity Check (The 'Standing Still' Test)\n",
    "    # Check if angle_diff is NaN where speed is low (0.5 yds/s threshold was used)\n",
    "    df_check = df_post_throw[df_post_throw['dir_derived'].isna()]\n",
    "    nan_count = len(df_check)\n",
    "    \n",
    "    # Check what percentage of NaNs meet the masking condition (s_derived < 0.5)\n",
    "    nan_check_success = (df_check['s_derived'] < 0.5).mean() * 100 if nan_count > 0 else 100\n",
    "    \n",
    "    markdown += f\"#### 1.1. NaN Integrity (Physics Masking)\\n\"\n",
    "    markdown += f\"- Total post-throw frames with calculated direction (`dir_derived`) = NaN: **{nan_count:,}**\\n\"\n",
    "    markdown += f\"- Percentage of those NaNs where speed (`s_derived`) was correctly masked (< 0.5 yds/s): **{nan_check_success:.2f}%**\\n\"\n",
    "    \n",
    "    if nan_check_success > 95:\n",
    "        markdown += \"üü¢ **PASS:** Physics mask is correctly applied. NaN values are generated only when player movement is below the noise threshold (standing still).\\n\"\n",
    "    else:\n",
    "        markdown += \"üî¥ **FAIL:** Potential issue. NaNs in direction exist when the player was moving. Check the physics engine.\\n\"\n",
    "\n",
    "    # 2. Vector Consistency Check (Should not have huge angle errors when moving fast)\n",
    "    # Filter for high-speed movement (where dir/angle is reliable)\n",
    "    df_fast = df_post_throw[df_post_throw['s_derived'] > 5.0].dropna(subset=['angle_diff'])\n",
    "    \n",
    "    avg_fast_angle_error = df_fast['angle_diff'].mean() if not df_fast.empty else np.nan\n",
    "    \n",
    "    markdown += f\"\\n#### 1.2. Vector Consistency (Movement Validation)\\n\"\n",
    "    markdown += f\"- Avg Angle Error (`angle_diff`) during high-speed pursuit (> 5.0 yds/s): **{avg_fast_angle_error:.2f} degrees**\\n\"\n",
    "    \n",
    "    if avg_fast_angle_error < 20:\n",
    "        markdown += \"üü¢ **PASS:** The average pursuit error for players actively running towards the ball is low. This confirms the physics derivation (`dir_derived`) and the ideal vector calculation (`dir_ideal`) are mathematically consistent.\\n\"\n",
    "    else:\n",
    "        markdown += \"üü° **WARNING:** The angle difference is high for fast players. Re-validate the angle conversion logic.\\n\"\n",
    "    \n",
    "    # 3. Stitch Point Continuity Check (Check the first frame of post-throw)\n",
    "    # The first frame of the output phase should never have a NaN physics value (as it follows pre-throw)\n",
    "    df_start_frame = df_post_throw[df_post_throw['event'] == 'pass_forward']\n",
    "    \n",
    "    start_nan_count = df_start_frame['s_derived'].isna().sum()\n",
    "    \n",
    "    markdown += f\"\\n#### 1.3. Pipeline Continuity Check\\n\"\n",
    "    markdown += f\"- Players with missing speed (`s_derived`) at the exact moment of 'pass_forward': **{start_nan_count}**\\n\"\n",
    "    \n",
    "    if start_nan_count == 0:\n",
    "        markdown += \"üü¢ **PASS:** The physics engine has successfully calculated movement vectors across the stitch point (pre-throw to post-throw) without creating a gap/NaN at the moment of the throw.\\n\"\n",
    "    else:\n",
    "        markdown += \"üî¥ **FAIL:** There is a discontinuity at the stitch point. Check the sorting in `preprocessing.py` or the `WINDOW` size in `physics_engine.py`.\\n\"\n",
    "    \n",
    "    display(Markdown(markdown))\n",
    "\n",
    "\n",
    "# --- Verification Cell 2: External Football Logic Checks ---\n",
    "\n",
    "def run_football_logic_checks(df_summary):\n",
    "    \"\"\"Verifies that the aggregated metrics align with expected football outcomes.\"\"\"\n",
    "    \n",
    "    markdown = \"### 2. External Football Logic and Metric Validation\\n\"\n",
    "    markdown += \"Testing the correlation between the new metric (`Reaction_Time_Frames`) and play outcome.\\n\\n\"\n",
    "\n",
    "    if df_summary is None or df_summary.empty:\n",
    "        markdown += \"üî¥ **DATA LOAD FAILURE.** Cannot run checks.\\n\"\n",
    "        print(markdown)\n",
    "        return\n",
    "\n",
    "    # Filter out plays where the defense was completely irrelevant (e.g., player stood still)\n",
    "    df_valid_metrics = df_summary.dropna(subset=['avg_pursuit_error'])\n",
    "    \n",
    "    # Calculate EPA for reference\n",
    "    df_valid_metrics['epa_impact'] = df_valid_metrics['damage_epa']\n",
    "    \n",
    "    # A. Perfect Play Test (Metric must reward good defense)\n",
    "    # Define a successful defensive play: Pass Incompletion AND low/negative EPA impact.\n",
    "    df_success = df_valid_metrics[\n",
    "        (df_valid_metrics['pass_result'] == 'I') & \n",
    "        (df_valid_metrics['is_punished'] == False)\n",
    "    ]\n",
    "    \n",
    "    avg_reaction_success = df_success['reaction_time_frames'].mean()\n",
    "    markdown += f\"#### 2.1. 'Perfect Play' Test (Incompletion/Neg EPA)\\n\"\n",
    "    markdown += f\"- Avg Reaction Time for Successful Defense (Should be low, < 5 frames): **{avg_reaction_success:.2f} frames**\\n\"\n",
    "    \n",
    "    if avg_reaction_success < 5:\n",
    "        markdown += \"üü¢ **PASS:** Defenders on successful plays reacted quickly (under 0.5s). The metric correctly identifies elite reaction time.\\n\"\n",
    "    else:\n",
    "        markdown += \"üü° **WARNING:** Successful plays are showing slow reaction times. Re-check the 30-degree lock threshold in `metrics.py`.\\n\"\n",
    "        \n",
    "    # B. Void Play Test (Metric must punish bad defense)\n",
    "    # Define a failed defensive play: Completion AND positive/high EPA impact.\n",
    "    df_failure = df_valid_metrics[\n",
    "        (df_valid_metrics['pass_result'] == 'C') & \n",
    "        (df_valid_metrics['is_punished'] == True)\n",
    "    ]\n",
    "    \n",
    "    # Calculate the percentage of these failures that were flagged as a 'Void'\n",
    "    void_flag_rate = df_failure['is_reaction_void'].mean() * 100\n",
    "    avg_reaction_failure = df_failure['reaction_time_frames'].mean()\n",
    "    \n",
    "    markdown += f\"\\n#### 2.2. 'Void Play' Test (Completion/Pos EPA)\\n\"\n",
    "    markdown += f\"- Avg Reaction Time for Failed Defense (Should be high, > 6 frames): **{avg_reaction_failure:.2f} frames**\\n\"\n",
    "    markdown += f\"- Percentage of Failed Plays Flagged as a Void (`is_reaction_void`): **{void_flag_rate:.2f}%**\\n\"\n",
    "    \n",
    "    if avg_reaction_failure > 6.0 and void_flag_rate > 50:\n",
    "        markdown += \"üü¢ **PASS:** Failed defensive plays are correctly correlated with high reaction times (late read). The 'Void' flag is highly correlated with poor outcomes.\\n\"\n",
    "    elif avg_reaction_failure > 6.0:\n",
    "        markdown += \"üü° **WARNING:** Reaction time is high, but the Void Flag rate is low. Consider lowering the threshold for `is_reaction_void` (e.g., > 5 frames).\\n\"\n",
    "    else:\n",
    "        markdown += \"üî¥ **FAIL:** The metric is not distinguishing successful defense from unsuccessful defense. Check the physics or aggregation logic.\\n\"\n",
    "\n",
    "    display(Markdown(markdown))\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "\n",
    "df_frame, df_summary = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4332662-29c6-4436-bec6-c96decc8498c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 1. Internal Data Integrity and Physics Validation\n",
       "Verifying that the derived metrics (S, Dir, A) are stable and flow correctly across all frames.\n",
       "\n",
       "#### 1.1. NaN Integrity (Physics Masking)\n",
       "- Total post-throw frames with calculated direction (`dir_derived`) = NaN: **2,147**\n",
       "- Percentage of those NaNs where speed (`s_derived`) was correctly masked (< 0.5 yds/s): **100.00%**\n",
       "üü¢ **PASS:** Physics mask is correctly applied. NaN values are generated only when player movement is below the noise threshold (standing still).\n",
       "\n",
       "#### 1.2. Vector Consistency (Movement Validation)\n",
       "- Avg Angle Error (`angle_diff`) during high-speed pursuit (> 5.0 yds/s): **39.35 degrees**\n",
       "üü° **WARNING:** The angle difference is high for fast players. Re-validate the angle conversion logic.\n",
       "\n",
       "#### 1.3. Pipeline Continuity Check\n",
       "- Players with missing speed (`s_derived`) at the exact moment of 'pass_forward': **0**\n",
       "üü¢ **PASS:** The physics engine has successfully calculated movement vectors across the stitch point (pre-throw to post-throw) without creating a gap/NaN at the moment of the throw.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14603/2455401503.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid_metrics['epa_impact'] = df_valid_metrics['damage_epa']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 2. External Football Logic and Metric Validation\n",
       "Testing the correlation between the new metric (`Reaction_Time_Frames`) and play outcome.\n",
       "\n",
       "#### 2.1. 'Perfect Play' Test (Incompletion/Neg EPA)\n",
       "- Avg Reaction Time for Successful Defense (Should be low, < 5 frames): **4.53 frames**\n",
       "üü¢ **PASS:** Defenders on successful plays reacted quickly (under 0.5s). The metric correctly identifies elite reaction time.\n",
       "\n",
       "#### 2.2. 'Void Play' Test (Completion/Pos EPA)\n",
       "- Avg Reaction Time for Failed Defense (Should be high, > 6 frames): **5.42 frames**\n",
       "- Percentage of Failed Plays Flagged as a Void (`is_reaction_void`): **51.40%**\n",
       "üî¥ **FAIL:** The metric is not distinguishing successful defense from unsuccessful defense. Check the physics or aggregation logic.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_internal_integrity_checks(df_frame)\n",
    "run_football_logic_checks(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169af7a-5683-4f0b-9a26-ecb7cdbab619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
